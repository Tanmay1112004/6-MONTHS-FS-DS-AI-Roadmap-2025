{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJWwhpvyJlt9"
      },
      "source": [
        "# WEB- SCRAPING ON xml file\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qTai6M3nJgMi"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FfeBLd6JhYS",
        "outputId": "801faafd-e663-47f6-89c3-fd600ed61159"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<>:28: SyntaxWarning: invalid escape sequence '\\['\n",
            "<>:28: SyntaxWarning: invalid escape sequence '\\['\n",
            "/tmp/ipython-input-323013414.py:28: SyntaxWarning: invalid escape sequence '\\['\n",
            "  return re.sub('\\[[^]]*\\]', '', text)\n",
            "/tmp/ipython-input-323013414.py:24: XMLParsedAsHTMLWarning: It looks like you're using an HTML parser to parse an XML document.\n",
            "\n",
            "Assuming this really is an XML document, what you're doing might work, but you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the Python package 'lxml' installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
            "\n",
            "If you want or need to use an HTML parser on this document, you can make this warning go away by filtering it. To do that, run this code before calling the BeautifulSoup constructor:\n",
            "\n",
            "    from bs4 import XMLParsedAsHTMLWarning\n",
            "    import warnings\n",
            "\n",
            "    warnings.filterwarnings(\"ignore\", category=XMLParsedAsHTMLWarning)\n",
            "\n",
            "  soup = BeautifulSoup(text, \"lxml\")\n"
          ]
        }
      ],
      "source": [
        "# XML scrapping for xml sheet\n",
        "\n",
        "import os\n",
        "# os.chdir(r\"/content/769952.xml\")\n",
        "\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "tree = ET.parse(\"/content/769952.xml\")\n",
        "root = tree.getroot()\n",
        "\n",
        "root=ET.tostring(root, encoding='utf8').decode('utf8')\n",
        "\n",
        "root\n",
        "\n",
        "import re, string, unicodedata\n",
        "import nltk\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import LancasterStemmer, WordNetLemmatizer\n",
        "\n",
        "def strip_html(text):\n",
        "    soup = BeautifulSoup(text, \"lxml\")\n",
        "    return soup.get_text()\n",
        "\n",
        "def remove_between_square_brackets(text):\n",
        "    return re.sub('\\[[^]]*\\]', '', text)\n",
        "\n",
        "def denoise_text(text):\n",
        "    text = strip_html(text)\n",
        "    text = remove_between_square_brackets(text)\n",
        "    text=re.sub('  ','',text)\n",
        "    return text\n",
        "\n",
        "sample = denoise_text(root)\n",
        "#print(sample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nf-o4a9dRJqd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "c12AaqYrS_AC",
        "outputId": "cf32b289-5f6e-401a-e016-bfb12b98a809"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.42.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.10.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.1.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.116.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (0.6.1)\n",
            "Requirement already satisfied: gradio-client==1.11.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.11.1)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.34.4)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.11.7)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.12.9)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.47.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.14.1)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.35.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.11.1->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.11.1->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (3.19.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (1.1.7)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0,>=0.33.5->gradio) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0,>=0.33.5->gradio) (2.5.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Requirement already satisfied: xmltodict in /usr/local/lib/python3.12/dist-packages (0.14.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (4.13.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (4.14.1)\n",
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://75fad0d0a80216fe22.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://75fad0d0a80216fe22.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://75fad0d0a80216fe22.gradio.live\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"XML_Data_Extractor_Visualizer.ipynb\n",
        "\n",
        "Automatically generated by Colaboratory.\n",
        "\n",
        "Original file is located at:\n",
        "    https://colab.research.google.com/drive/1YrQh3p3_5J3v0_3p5_6_7v8w9x0y1z2\n",
        "\"\"\"\n",
        "\n",
        "!pip install gradio\n",
        "!pip install xmltodict\n",
        "!pip install beautifulsoup4\n",
        "\n",
        "import gradio as gr\n",
        "import xml.etree.ElementTree as ET\n",
        "import xmltodict\n",
        "import json\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "\n",
        "def parse_xml(xml_content, input_type):\n",
        "    \"\"\"\n",
        "    Parse XML content from either file upload or text input\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if input_type == \"file\":\n",
        "            # Ensure the file object is read correctly\n",
        "            if hasattr(xml_content, 'name'):\n",
        "                with open(xml_content.name, 'r', encoding='utf-8') as f:\n",
        "                    xml_string = f.read()\n",
        "            else:\n",
        "                 return None, None, None, \"Invalid file object provided.\"\n",
        "        else:\n",
        "            xml_string = xml_content\n",
        "\n",
        "        # Parse with ElementTree\n",
        "        root = ET.fromstring(xml_string)\n",
        "\n",
        "        # Convert to dict for easier processing\n",
        "        xml_dict = xmltodict.parse(xml_string)\n",
        "\n",
        "        return root, xml_dict, xml_string, None\n",
        "    except Exception as e:\n",
        "        return None, None, None, str(e)\n",
        "\n",
        "def extract_xml_structure(xml_content, input_type):\n",
        "    \"\"\"\n",
        "    Extract and display the structure of the XML document\n",
        "    \"\"\"\n",
        "    root, xml_dict, xml_string, error = parse_xml(xml_content, input_type)\n",
        "\n",
        "    if error:\n",
        "        return f\"Error parsing XML: {error}\"\n",
        "\n",
        "    # Create a structure visualization\n",
        "    structure = []\n",
        "\n",
        "    def traverse(node, depth=0):\n",
        "        structure.append(\"  \" * depth + f\"<{node.tag}>\")\n",
        "        for child in node:\n",
        "            traverse(child, depth + 1)\n",
        "        if not list(node):  # If no children, show text content if exists\n",
        "            if node.text and node.text.strip():\n",
        "                structure.append(\"  \" * (depth + 1) + f\"Text: {node.text.strip()}\")\n",
        "\n",
        "    traverse(root)\n",
        "    return \"\\n\".join(structure)\n",
        "\n",
        "def extract_xml_data(xml_content, input_type):\n",
        "    \"\"\"\n",
        "    Extract data from XML and present in a readable format\n",
        "    \"\"\"\n",
        "    root, xml_dict, xml_string, error = parse_xml(xml_content, input_type)\n",
        "\n",
        "    if error:\n",
        "        return f\"Error parsing XML: {error}\", \"\"\n",
        "\n",
        "    # Convert to pretty JSON for display\n",
        "    json_data = json.dumps(xml_dict, indent=2)\n",
        "\n",
        "    # Create a simplified table view for common XML structures\n",
        "    tables = []\n",
        "\n",
        "    # Try to find repeating elements that might form a table\n",
        "    def find_tables(node, path=\"\"):\n",
        "        if len(node) > 0:\n",
        "            # Check if all children have the same structure\n",
        "            child_tags = [child.tag for child in node]\n",
        "            if len(set(child_tags)) == 1 and len(child_tags) > 1:\n",
        "                # This might be a table-like structure\n",
        "                columns = set()\n",
        "                for child in node:\n",
        "                    for grandchild in child:\n",
        "                        columns.add(grandchild.tag)\n",
        "\n",
        "                if columns:\n",
        "                    # Create a table\n",
        "                    table_data = []\n",
        "                    for child in node:\n",
        "                        row = {}\n",
        "                        for grandchild in child:\n",
        "                            row[grandchild.tag] = grandchild.text if grandchild.text else \"\"\n",
        "                        table_data.append(row)\n",
        "\n",
        "                    if table_data:\n",
        "                        df = pd.DataFrame(table_data)\n",
        "                        tables.append((f\"Table from {path}/{node.tag}\", df))\n",
        "\n",
        "            # Recursively process children\n",
        "            for child in node:\n",
        "                find_tables(child, f\"{path}/{node.tag}\")\n",
        "\n",
        "    find_tables(root)\n",
        "\n",
        "    # Format tables for display\n",
        "    tables_html = \"<h2>Extracted Tables</h2>\"\n",
        "    if tables:\n",
        "        for name, df in tables:\n",
        "            tables_html += f\"<h3>{name}</h3>\"\n",
        "            tables_html += df.to_html()\n",
        "    else:\n",
        "        tables_html += \"<p>No table-like structures detected</p>\"\n",
        "\n",
        "    return json_data, tables_html\n",
        "\n",
        "def visualize_xml(xml_content, input_type):\n",
        "    \"\"\"\n",
        "    Create visualizations from XML data\n",
        "    \"\"\"\n",
        "    root, xml_dict, xml_string, error = parse_xml(xml_content, input_type)\n",
        "\n",
        "    if error:\n",
        "        return f\"Error parsing XML: {error}\"\n",
        "\n",
        "    # Count elements by tag\n",
        "    tag_count = defaultdict(int)\n",
        "\n",
        "    def count_tags(node):\n",
        "        tag_count[node.tag] += 1\n",
        "        for child in node:\n",
        "            count_tags(child)\n",
        "\n",
        "    count_tags(root)\n",
        "\n",
        "    # Create a bar chart of tag frequencies\n",
        "    if tag_count:\n",
        "        fig = px.bar(x=list(tag_count.keys()), y=list(tag_count.values()),\n",
        "                     labels={'x': 'XML Tags', 'y': 'Count'},\n",
        "                     title='Frequency of XML Tags')\n",
        "        return fig\n",
        "    else:\n",
        "        return \"No data available for visualization\"\n",
        "\n",
        "def clean_xml(xml_content, input_type):\n",
        "    \"\"\"\n",
        "    Clean and format XML content\n",
        "    \"\"\"\n",
        "    root, xml_dict, xml_string, error = parse_xml(xml_content, input_type)\n",
        "\n",
        "    if error:\n",
        "        return f\"Error parsing XML: {error}\"\n",
        "\n",
        "    # Pretty print the XML\n",
        "    soup = BeautifulSoup(xml_string, 'xml')\n",
        "    pretty_xml = soup.prettify()\n",
        "\n",
        "    return pretty_xml\n",
        "\n",
        "# Create the Gradio interface\n",
        "with gr.Blocks(theme=gr.themes.Soft(), title=\"XML Data Extractor and Visualizer\") as demo:\n",
        "    gr.Markdown(\"\"\"\n",
        "    # XML Data Extractor and Visualizer\n",
        "    Upload an XML file or paste XML content to explore its structure, extract data, and create visualizations.\n",
        "    \"\"\")\n",
        "\n",
        "    with gr.Tab(\"XML Input\"):\n",
        "        input_type = gr.Radio([\"file\", \"text\"], value=\"file\", label=\"Input Type\")\n",
        "        xml_input = gr.File(label=\"Upload XML File\", file_types=[\".xml\"])\n",
        "        xml_text = gr.Textbox(label=\"Or Paste XML Content\", lines=10, visible=False)\n",
        "\n",
        "        def toggle_input(choice):\n",
        "            if choice == \"file\":\n",
        "                return gr.File(visible=True), gr.Textbox(visible=False)\n",
        "            else:\n",
        "                return gr.File(visible=False), gr.Textbox(visible=True)\n",
        "\n",
        "        input_type.change(toggle_input, input_type, [xml_input, xml_text])\n",
        "\n",
        "    with gr.Tab(\"XML Structure\"):\n",
        "        structure_btn = gr.Button(\"Extract Structure\")\n",
        "        structure_output = gr.Textbox(label=\"XML Structure\", lines=15)\n",
        "\n",
        "    with gr.Tab(\"Data Extraction\"):\n",
        "        extract_btn = gr.Button(\"Extract Data\")\n",
        "        with gr.Row():\n",
        "            json_output = gr.Textbox(label=\"JSON Representation\", lines=15)\n",
        "            table_output = gr.HTML(label=\"Tabular Data\")\n",
        "\n",
        "    with gr.Tab(\"Visualization\"):\n",
        "        viz_btn = gr.Button(\"Create Visualization\")\n",
        "        viz_output = gr.Plot(label=\"Tag Frequency Visualization\")\n",
        "\n",
        "    with gr.Tab(\"XML Cleaner\"):\n",
        "        clean_btn = gr.Button(\"Clean and Format XML\")\n",
        "        clean_output = gr.Code(label=\"Formatted XML\", lines=15)\n",
        "\n",
        "    # Set up event handlers\n",
        "    structure_btn.click(\n",
        "        extract_xml_structure,\n",
        "        inputs=[xml_input, input_type],\n",
        "        outputs=structure_output\n",
        "    )\n",
        "\n",
        "    extract_btn.click(\n",
        "        extract_xml_data,\n",
        "        inputs=[xml_input, input_type],\n",
        "        outputs=[json_output, table_output]\n",
        "    )\n",
        "\n",
        "    viz_btn.click(\n",
        "        visualize_xml,\n",
        "        inputs=[xml_input, input_type],\n",
        "        outputs=viz_output\n",
        "    )\n",
        "\n",
        "    clean_btn.click(\n",
        "        clean_xml,\n",
        "        inputs=[xml_input, input_type],\n",
        "        outputs=clean_output\n",
        "    )\n",
        "\n",
        "# Launch the interface\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch(debug=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C0_E8TGES-9q"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CYcm_GWzS-4x",
        "outputId": "46246e71-61cd-4a71-e15c-a82f84609976"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.42.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.10.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.1.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.116.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (0.6.1)\n",
            "Requirement already satisfied: gradio-client==1.11.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.11.1)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.34.4)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.11.7)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.12.9)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.47.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.14.1)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.35.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.11.1->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.11.1->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (3.19.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (1.1.7)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0,>=0.33.5->gradio) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0,>=0.33.5->gradio) (2.5.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Requirement already satisfied: xmltodict in /usr/local/lib/python3.12/dist-packages (0.14.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (4.13.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (4.14.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (5.24.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly) (8.5.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from plotly) (25.0)\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://56bcbbe02904c0a8c1.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://56bcbbe02904c0a8c1.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://56bcbbe02904c0a8c1.gradio.live\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"XML_Data_Extractor_Visualizer.ipynb\n",
        "\n",
        "Automatically generated by Colaboratory.\n",
        "\n",
        "Original file is located at:\n",
        "    https://colab.research.google.com/drive/1YrQh3p3_5J3v0_3p5_6_7v8w9x0y1z2\n",
        "\"\"\"\n",
        "\n",
        "!pip install gradio\n",
        "!pip install xmltodict\n",
        "!pip install beautifulsoup4\n",
        "!pip install plotly\n",
        "\n",
        "import gradio as gr\n",
        "import xml.etree.ElementTree as ET\n",
        "import xmltodict\n",
        "import json\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "import tempfile\n",
        "import os\n",
        "\n",
        "def parse_xml(xml_content, input_type):\n",
        "    \"\"\"\n",
        "    Parse XML content from either file upload or text input\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if input_type == \"file\":\n",
        "            if xml_content is None:\n",
        "                return None, None, None, \"No file uploaded\"\n",
        "            with open(xml_content.name, 'r', encoding='utf-8') as f:\n",
        "                xml_string = f.read()\n",
        "        else:\n",
        "            xml_string = xml_content\n",
        "            if not xml_string.strip():\n",
        "                return None, None, None, \"No XML content provided\"\n",
        "\n",
        "        # Parse with ElementTree\n",
        "        root = ET.fromstring(xml_string)\n",
        "\n",
        "        # Convert to dict for easier processing\n",
        "        xml_dict = xmltodict.parse(xml_string)\n",
        "\n",
        "        return root, xml_dict, xml_string, None\n",
        "    except Exception as e:\n",
        "        return None, None, None, str(e)\n",
        "\n",
        "def extract_xml_structure(xml_content, input_type):\n",
        "    \"\"\"\n",
        "    Extract and display the structure of the XML document\n",
        "    \"\"\"\n",
        "    root, xml_dict, xml_string, error = parse_xml(xml_content, input_type)\n",
        "\n",
        "    if error:\n",
        "        return f\"Error parsing XML: {error}\"\n",
        "\n",
        "    # Create a structure visualization\n",
        "    structure = []\n",
        "\n",
        "    def traverse(node, depth=0):\n",
        "        structure.append(\"  \" * depth + f\"<{node.tag}>\")\n",
        "        # Add attributes if any\n",
        "        if node.attrib:\n",
        "            for attr, value in node.attrib.items():\n",
        "                structure.append(\"  \" * (depth + 1) + f\"@{attr}: {value}\")\n",
        "        for child in node:\n",
        "            traverse(child, depth + 1)\n",
        "        if not list(node):  # If no children, show text content if exists\n",
        "            if node.text and node.text.strip():\n",
        "                structure.append(\"  \" * (depth + 1) + f\"Text: {node.text.strip()}\")\n",
        "        structure.append(\"  \" * depth + f\"</{node.tag}>\")\n",
        "\n",
        "    traverse(root)\n",
        "    return \"\\n\".join(structure)\n",
        "\n",
        "def extract_xml_data(xml_content, input_type):\n",
        "    \"\"\"\n",
        "    Extract data from XML and present in a readable format\n",
        "    \"\"\"\n",
        "    root, xml_dict, xml_string, error = parse_xml(xml_content, input_type)\n",
        "\n",
        "    if error:\n",
        "        return f\"Error parsing XML: {error}\", \"<p>Error parsing XML</p>\"\n",
        "\n",
        "    # Convert to pretty JSON for display\n",
        "    try:\n",
        "        json_data = json.dumps(xml_dict, indent=2)\n",
        "    except:\n",
        "        json_data = \"Could not convert to JSON format\"\n",
        "\n",
        "    # Extract all data from XML in a structured way\n",
        "    extracted_data = []\n",
        "\n",
        "    def extract_elements(node, path=\"\"):\n",
        "        current_path = f\"{path}/{node.tag}\" if path else node.tag\n",
        "\n",
        "        # Extract element data\n",
        "        element_data = {\n",
        "            \"path\": current_path,\n",
        "            \"tag\": node.tag,\n",
        "            \"attributes\": dict(node.attrib),\n",
        "            \"text\": node.text.strip() if node.text and node.text.strip() else None,\n",
        "            \"children\": len(list(node))\n",
        "        }\n",
        "        extracted_data.append(element_data)\n",
        "\n",
        "        # Process children\n",
        "        for child in node:\n",
        "            extract_elements(child, current_path)\n",
        "\n",
        "    extract_elements(root)\n",
        "\n",
        "    # Create a DataFrame for display\n",
        "    df = pd.DataFrame(extracted_data)\n",
        "\n",
        "    # Create HTML table\n",
        "    if not df.empty:\n",
        "        table_html = df.to_html(classes='table table-striped', index=False, escape=False)\n",
        "    else:\n",
        "        table_html = \"<p>No data could be extracted from the XML</p>\"\n",
        "\n",
        "    return json_data, table_html\n",
        "\n",
        "def extract_xml_data_as_table(xml_content, input_type):\n",
        "    \"\"\"\n",
        "    Extract data from XML and present in a tabular format\n",
        "    \"\"\"\n",
        "    root, xml_dict, xml_string, error = parse_xml(xml_content, input_type)\n",
        "\n",
        "    if error:\n",
        "        return f\"Error parsing XML: {error}\", \"<p>Error parsing XML</p>\"\n",
        "\n",
        "    # Find repeating elements that could form a table\n",
        "    tables = []\n",
        "\n",
        "    def find_table_data(node, path=\"\"):\n",
        "        # If this node has children and all children have the same tag, it might be a table\n",
        "        children = list(node)\n",
        "        if children:\n",
        "            child_tags = [child.tag for child in children]\n",
        "            if len(set(child_tags)) == 1 and len(children) > 1:\n",
        "                # This looks like a table row structure\n",
        "                table_rows = []\n",
        "                for child in children:\n",
        "                    row = {\"_row_type\": child.tag}\n",
        "                    for grandchild in child:\n",
        "                        row[grandchild.tag] = grandchild.text.strip() if grandchild.text and grandchild.text.strip() else \"\"\n",
        "                    table_rows.append(row)\n",
        "\n",
        "                if table_rows:\n",
        "                    tables.append({\n",
        "                        \"name\": f\"{path}/{node.tag}\",\n",
        "                        \"data\": table_rows\n",
        "                    })\n",
        "\n",
        "        # Recursively process children\n",
        "        for child in children:\n",
        "            find_table_data(child, f\"{path}/{node.tag}\")\n",
        "\n",
        "    find_table_data(root)\n",
        "\n",
        "    # Generate HTML for tables\n",
        "    tables_html = \"<h2>Extracted Data Tables</h2>\"\n",
        "\n",
        "    if tables:\n",
        "        for i, table in enumerate(tables):\n",
        "            df = pd.DataFrame(table[\"data\"])\n",
        "            tables_html += f\"<h3>Table {i+1}: {table['name']}</h3>\"\n",
        "            tables_html += df.to_html(classes='table table-striped', index=False)\n",
        "    else:\n",
        "        tables_html += \"<p>No table-like structures found. Showing all elements:</p>\"\n",
        "\n",
        "        # Fallback: show all elements in a table\n",
        "        all_data = []\n",
        "\n",
        "        def extract_all_elements(node, path=\"\"):\n",
        "            current_path = f\"{path}/{node.tag}\" if path else node.tag\n",
        "            element_data = {\n",
        "                \"Path\": current_path,\n",
        "                \"Tag\": node.tag,\n",
        "                \"Attributes\": str(node.attrib),\n",
        "                \"Text\": node.text.strip() if node.text and node.text.strip() else \"\",\n",
        "                \"Children\": len(list(node))\n",
        "            }\n",
        "            all_data.append(element_data)\n",
        "\n",
        "            for child in node:\n",
        "                extract_all_elements(child, current_path)\n",
        "\n",
        "        extract_all_elements(root)\n",
        "        df = pd.DataFrame(all_data)\n",
        "        tables_html += df.to_html(classes='table table-striped', index=False)\n",
        "\n",
        "    return tables_html\n",
        "\n",
        "def visualize_xml(xml_content, input_type):\n",
        "    \"\"\"\n",
        "    Create visualizations from XML data\n",
        "    \"\"\"\n",
        "    root, xml_dict, xml_string, error = parse_xml(xml_content, input_type)\n",
        "\n",
        "    if error:\n",
        "        return f\"Error parsing XML: {error}\"\n",
        "\n",
        "    # Count elements by tag\n",
        "    tag_count = defaultdict(int)\n",
        "\n",
        "    def count_tags(node):\n",
        "        tag_count[node.tag] += 1\n",
        "        for child in node:\n",
        "            count_tags(child)\n",
        "\n",
        "    count_tags(root)\n",
        "\n",
        "    # Create a bar chart of tag frequencies\n",
        "    if tag_count:\n",
        "        fig = px.bar(x=list(tag_count.keys()), y=list(tag_count.values()),\n",
        "                     labels={'x': 'XML Tags', 'y': 'Count'},\n",
        "                     title='Frequency of XML Tags')\n",
        "        return fig\n",
        "    else:\n",
        "        return \"No data available for visualization\"\n",
        "\n",
        "def clean_xml(xml_content, input_type):\n",
        "    \"\"\"\n",
        "    Clean and format XML content\n",
        "    \"\"\"\n",
        "    if input_type == \"file\":\n",
        "        if xml_content is None:\n",
        "            return \"No file uploaded\"\n",
        "        with open(xml_content.name, 'r', encoding='utf-8') as f:\n",
        "            xml_string = f.read()\n",
        "    else:\n",
        "        xml_string = xml_content\n",
        "        if not xml_string.strip():\n",
        "            return \"No XML content provided\"\n",
        "\n",
        "    # Pretty print the XML\n",
        "    try:\n",
        "        soup = BeautifulSoup(xml_string, 'xml')\n",
        "        pretty_xml = soup.prettify()\n",
        "        return pretty_xml\n",
        "    except Exception as e:\n",
        "        return f\"Error formatting XML: {str(e)}\"\n",
        "\n",
        "# Create the Gradio interface\n",
        "with gr.Blocks(theme=gr.themes.Soft(), title=\"XML Data Extractor and Visualizer\") as demo:\n",
        "    gr.Markdown(\"\"\"\n",
        "    # 🔍 XML Data Extractor and Visualizer\n",
        "    Upload an XML file or paste XML content to explore its structure, extract data, and create visualizations.\n",
        "    \"\"\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            input_type = gr.Radio([\"file\", \"text\"], value=\"file\", label=\"Input Type\")\n",
        "            xml_input = gr.File(label=\"Upload XML File\", file_types=[\".xml\"])\n",
        "            xml_text = gr.Textbox(label=\"Or Paste XML Content\", lines=10, visible=False)\n",
        "\n",
        "            def toggle_input(choice):\n",
        "                if choice == \"file\":\n",
        "                    return gr.File(visible=True), gr.Textbox(visible=False)\n",
        "                else:\n",
        "                    return gr.File(visible=False), gr.Textbox(visible=True)\n",
        "\n",
        "            input_type.change(toggle_input, input_type, [xml_input, xml_text])\n",
        "\n",
        "        with gr.Column():\n",
        "            gr.Markdown(\"\"\"\n",
        "            ### 📊 What you can do:\n",
        "            - **View Structure**: See the hierarchical structure of your XML\n",
        "            - **Extract Data**: Convert XML to JSON and detect table structures\n",
        "            - **Visualize**: Create charts showing tag frequencies\n",
        "            - **Clean XML**: Format and prettify your XML code\n",
        "\n",
        "            ### 🚀 Try with this sample XML:\n",
        "            ```xml\n",
        "            <catalog>\n",
        "              <book id=\"101\">\n",
        "                <author>John Doe</author>\n",
        "                <title>XML Guide</title>\n",
        "                <price>29.99</price>\n",
        "              </book>\n",
        "              <book id=\"102\">\n",
        "                <author>Jane Smith</author>\n",
        "                <title>Python Programming</title>\n",
        "                <price>39.99</price>\n",
        "              </book>\n",
        "            </catalog>\n",
        "            ```\n",
        "            \"\"\")\n",
        "\n",
        "    with gr.Tab(\"📁 XML Structure\"):\n",
        "        gr.Markdown(\"### XML Document Structure\")\n",
        "        structure_btn = gr.Button(\"Extract Structure\", variant=\"primary\")\n",
        "        structure_output = gr.Code(label=\"XML Structure\", language=\"markdown\", lines=15)\n",
        "\n",
        "    with gr.Tab(\"📊 Data Extraction\"):\n",
        "        gr.Markdown(\"### Extracted Data from XML\")\n",
        "        extract_btn = gr.Button(\"Extract Data\", variant=\"primary\")\n",
        "        with gr.Row():\n",
        "            json_output = gr.Code(label=\"JSON Representation\", language=\"json\", lines=15)\n",
        "            table_output = gr.HTML(label=\"Tabular Data\")\n",
        "\n",
        "    with gr.Tab(\"📈 Visualization\"):\n",
        "        gr.Markdown(\"### XML Data Visualization\")\n",
        "        viz_btn = gr.Button(\"Create Visualization\", variant=\"primary\")\n",
        "        viz_output = gr.Plot(label=\"Tag Frequency Visualization\")\n",
        "\n",
        "    with gr.Tab(\"✨ XML Cleaner\"):\n",
        "        gr.Markdown(\"### Clean and Format XML\")\n",
        "        clean_btn = gr.Button(\"Clean and Format XML\", variant=\"primary\")\n",
        "        clean_output = gr.Code(label=\"Formatted XML\", language=\"html\", lines=15)\n",
        "\n",
        "    # Set up event handlers\n",
        "    structure_btn.click(\n",
        "        extract_xml_structure,\n",
        "        inputs=[xml_input, input_type],\n",
        "        outputs=structure_output\n",
        "    )\n",
        "\n",
        "    extract_btn.click(\n",
        "        extract_xml_data,\n",
        "        inputs=[xml_input, input_type],\n",
        "        outputs=[json_output, table_output]\n",
        "    )\n",
        "\n",
        "    viz_btn.click(\n",
        "        visualize_xml,\n",
        "        inputs=[xml_input, input_type],\n",
        "        outputs=viz_output\n",
        "    )\n",
        "\n",
        "    clean_btn.click(\n",
        "        clean_xml,\n",
        "        inputs=[xml_input, input_type],\n",
        "        outputs=clean_output\n",
        "    )\n",
        "\n",
        "# For Google Colab, we need to handle the launch differently\n",
        "def launch_in_colab():\n",
        "    # Create a public link\n",
        "    demo.launch(share=True, debug=True)\n",
        "\n",
        "# Launch the interface\n",
        "if __name__ == \"__main__\":\n",
        "    # This will work in both Colab and local environments\n",
        "    try:\n",
        "        import google.colab\n",
        "        IN_COLAB = True\n",
        "    except:\n",
        "        IN_COLAB = False\n",
        "\n",
        "    if IN_COLAB:\n",
        "        launch_in_colab()\n",
        "    else:\n",
        "        demo.launch(debug=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9nSeWPsyS-2P"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "96Ot85flXIqX",
        "outputId": "f0b0f738-154d-4f5b-98fe-3fbc27603d09"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.42.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.10.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.1.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.116.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (0.6.1)\n",
            "Requirement already satisfied: gradio-client==1.11.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.11.1)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.34.4)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.11.7)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.12.9)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.47.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.14.1)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.35.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.11.1->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.11.1->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (3.19.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (1.1.7)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0,>=0.33.5->gradio) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0,>=0.33.5->gradio) (2.5.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Requirement already satisfied: xmltodict in /usr/local/lib/python3.12/dist-packages (0.14.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (4.13.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (4.14.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (5.24.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly) (8.5.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from plotly) (25.0)\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://7b180ba37e00500d9a.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://7b180ba37e00500d9a.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://7b180ba37e00500d9a.gradio.live\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"XML_Data_Extractor_Visualizer.ipynb\n",
        "\n",
        "Automatically generated by Colaboratory.\n",
        "\n",
        "Original file is located at:\n",
        "    https://colab.research.google.com/drive/1YrQh3p3_5J3v0_3p5_6_7v8w9x0y1z2\n",
        "\"\"\"\n",
        "\n",
        "!pip install gradio\n",
        "!pip install xmltodict\n",
        "!pip install beautifulsoup4\n",
        "!pip install plotly\n",
        "\n",
        "import gradio as gr\n",
        "import xml.etree.ElementTree as ET\n",
        "import xmltodict\n",
        "import json\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "import tempfile\n",
        "import os\n",
        "\n",
        "def parse_xml(xml_content, input_type):\n",
        "    \"\"\"\n",
        "    Parse XML content from either file upload or text input\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if input_type == \"file\":\n",
        "            if xml_content is None:\n",
        "                return None, None, None, \"No file uploaded\"\n",
        "            with open(xml_content.name, 'r', encoding='utf-8') as f:\n",
        "                xml_string = f.read()\n",
        "        else:\n",
        "            xml_string = xml_content\n",
        "            if not xml_string.strip():\n",
        "                return None, None, None, \"No XML content provided\"\n",
        "\n",
        "        # Parse with ElementTree\n",
        "        root = ET.fromstring(xml_string)\n",
        "\n",
        "        # Convert to dict for easier processing\n",
        "        xml_dict = xmltodict.parse(xml_string)\n",
        "\n",
        "        return root, xml_dict, xml_string, None\n",
        "    except Exception as e:\n",
        "        return None, None, None, str(e)\n",
        "\n",
        "def extract_xml_structure(xml_content, input_type):\n",
        "    \"\"\"\n",
        "    Extract and display the structure of the XML document\n",
        "    \"\"\"\n",
        "    root, xml_dict, xml_string, error = parse_xml(xml_content, input_type)\n",
        "\n",
        "    if error:\n",
        "        return f\"Error parsing XML: {error}\"\n",
        "\n",
        "    # Create a structure visualization\n",
        "    structure = []\n",
        "\n",
        "    def traverse(node, depth=0):\n",
        "        structure.append(\"  \" * depth + f\"<{node.tag}>\")\n",
        "        # Add attributes if any\n",
        "        if node.attrib:\n",
        "            for attr, value in node.attrib.items():\n",
        "                structure.append(\"  \" * (depth + 1) + f\"@{attr}: {value}\")\n",
        "        for child in node:\n",
        "            traverse(child, depth + 1)\n",
        "        if not list(node):  # If no children, show text content if exists\n",
        "            if node.text and node.text.strip():\n",
        "                structure.append(\"  \" * (depth + 1) + f\"Text: {node.text.strip()}\")\n",
        "        structure.append(\"  \" * depth + f\"</{node.tag}>\")\n",
        "\n",
        "    traverse(root)\n",
        "    return \"\\n\".join(structure)\n",
        "\n",
        "def extract_xml_data(xml_content, input_type):\n",
        "    \"\"\"\n",
        "    Extract data from XML and present in a readable format\n",
        "    \"\"\"\n",
        "    root, xml_dict, xml_string, error = parse_xml(xml_content, input_type)\n",
        "\n",
        "    if error:\n",
        "        return f\"Error parsing XML: {error}\", \"<p>Error parsing XML</p>\"\n",
        "\n",
        "    # Convert to pretty JSON for display\n",
        "    try:\n",
        "        json_data = json.dumps(xml_dict, indent=2)\n",
        "    except:\n",
        "        json_data = \"Could not convert to JSON format\"\n",
        "\n",
        "    # Extract all data from XML in a structured way\n",
        "    extracted_data = []\n",
        "\n",
        "    def extract_elements(node, path=\"\"):\n",
        "        current_path = f\"{path}/{node.tag}\" if path else node.tag\n",
        "\n",
        "        # Extract element data\n",
        "        element_data = {\n",
        "            \"path\": current_path,\n",
        "            \"tag\": node.tag,\n",
        "            \"attributes\": dict(node.attrib),\n",
        "            \"text\": node.text.strip() if node.text and node.text.strip() else None,\n",
        "            \"children\": len(list(node))\n",
        "        }\n",
        "        extracted_data.append(element_data)\n",
        "\n",
        "        # Process children\n",
        "        for child in node:\n",
        "            extract_elements(child, current_path)\n",
        "\n",
        "    extract_elements(root)\n",
        "\n",
        "    # Create a DataFrame for display\n",
        "    df = pd.DataFrame(extracted_data)\n",
        "\n",
        "    # Create HTML table\n",
        "    if not df.empty:\n",
        "        table_html = df.to_html(classes='table table-striped', index=False, escape=False)\n",
        "    else:\n",
        "        table_html = \"<p>No data could be extracted from the XML</p>\"\n",
        "\n",
        "    return json_data, table_html\n",
        "\n",
        "def generate_insights(xml_content, input_type):\n",
        "    \"\"\"\n",
        "    Generate meaningful insights about the XML structure and content\n",
        "    \"\"\"\n",
        "    root, xml_dict, xml_string, error = parse_xml(xml_content, input_type)\n",
        "\n",
        "    if error:\n",
        "        return f\"<p style='color: red;'>Error parsing XML: {error}</p>\"\n",
        "\n",
        "    insights_html = \"<div style='font-family: Arial, sans-serif;'>\"\n",
        "    insights_html += \"<h2 style='color: #2E86AB;'>📊 XML Insights & Analysis</h2>\"\n",
        "\n",
        "    # Basic statistics\n",
        "    total_elements = 0\n",
        "    elements_with_attributes = 0\n",
        "    elements_with_text = 0\n",
        "    max_depth = 0\n",
        "    tag_counts = defaultdict(int)\n",
        "    attribute_counts = defaultdict(int)\n",
        "\n",
        "    def analyze_node(node, depth=0):\n",
        "        nonlocal total_elements, elements_with_attributes, elements_with_text, max_depth\n",
        "        total_elements += 1\n",
        "        tag_counts[node.tag] += 1\n",
        "        max_depth = max(max_depth, depth)\n",
        "\n",
        "        if node.attrib:\n",
        "            elements_with_attributes += 1\n",
        "            for attr in node.attrib:\n",
        "                attribute_counts[attr] += 1\n",
        "\n",
        "        if node.text and node.text.strip():\n",
        "            elements_with_text += 1\n",
        "\n",
        "        for child in node:\n",
        "            analyze_node(child, depth + 1)\n",
        "\n",
        "    analyze_node(root)\n",
        "\n",
        "    # Generate insights\n",
        "    insights_html += f\"<h3 style='color: #A23B72;'>📈 Basic Statistics</h3>\"\n",
        "    insights_html += f\"<ul>\"\n",
        "    insights_html += f\"<li>Total Elements: <b>{total_elements}</b></li>\"\n",
        "    insights_html += f\"<li>Maximum Depth: <b>{max_depth}</b> levels</li>\"\n",
        "    insights_html += f\"<li>Elements with Attributes: <b>{elements_with_attributes}</b> ({elements_with_attributes/total_elements*100:.1f}%)</li>\"\n",
        "    insights_html += f\"<li>Elements with Text Content: <b>{elements_with_text}</b> ({elements_with_text/total_elements*100:.1f}%)</li>\"\n",
        "    insights_html += f\"</ul>\"\n",
        "\n",
        "    # Tag frequency analysis\n",
        "    insights_html += f\"<h3 style='color: #A23B72;'>🏷️ Tag Frequency</h3>\"\n",
        "    if tag_counts:\n",
        "        insights_html += f\"<p>Unique Tags: <b>{len(tag_counts)}</b></p>\"\n",
        "        insights_html += \"<table style='width: 100%; border-collapse: collapse;'><tr><th style='border: 1px solid #ddd; padding: 8px; background-color: #f2f2f2;'>Tag</th><th style='border: 1px solid #ddd; padding: 8px; background-color: #f2f2f2;'>Count</th><th style='border: 1px solid #ddd; padding: 8px; background-color: #f2f2f2;'>Percentage</th></tr>\"\n",
        "\n",
        "        for tag, count in sorted(tag_counts.items(), key=lambda x: x[1], reverse=True)[:10]:\n",
        "            percentage = (count / total_elements) * 100\n",
        "            insights_html += f\"<tr><td style='border: 1px solid #ddd; padding: 8px;'>{tag}</td><td style='border: 1px solid #ddd; padding: 8px;'>{count}</td><td style='border: 1px solid #ddd; padding: 8px;'>{percentage:.1f}%</td></tr>\"\n",
        "\n",
        "        insights_html += \"</table>\"\n",
        "\n",
        "        if len(tag_counts) > 10:\n",
        "            insights_html += f\"<p>... and {len(tag_counts) - 10} more tags</p>\"\n",
        "\n",
        "    # Attribute analysis\n",
        "    if attribute_counts:\n",
        "        insights_html += f\"<h3 style='color: #A23B72;'>🔗 Attributes</h3>\"\n",
        "        insights_html += f\"<p>Unique Attributes: <b>{len(attribute_counts)}</b></p>\"\n",
        "        insights_html += \"<table style='width: 100%; border-collapse: collapse;'><tr><th style='border: 1px solid #ddd; padding: 8px; background-color: #f2f2f2;'>Attribute</th><th style='border: 1px solid #ddd; padding: 8px; background-color: #f2f2f2;'>Count</th></tr>\"\n",
        "\n",
        "        for attr, count in sorted(attribute_counts.items(), key=lambda x: x[1], reverse=True)[:10]:\n",
        "            insights_html += f\"<tr><td style='border: 1px solid #ddd; padding: 8px;'>{attr}</td><td style='border: 1px solid #ddd; padding: 8px;'>{count}</td></tr>\"\n",
        "\n",
        "        insights_html += \"</table>\"\n",
        "\n",
        "        if len(attribute_counts) > 10:\n",
        "            insights_html += f\"<p>... and {len(attribute_counts) - 10} more attributes</p>\"\n",
        "\n",
        "    # Structural insights\n",
        "    insights_html += f\"<h3 style='color: #A23B72;'>🏗️ Structural Insights</h3>\"\n",
        "\n",
        "    # Check for potential data tables\n",
        "    potential_tables = []\n",
        "\n",
        "    def find_potential_tables(node, path=\"\"):\n",
        "        children = list(node)\n",
        "        if children:\n",
        "            child_tags = [child.tag for child in children]\n",
        "            if len(set(child_tags)) == 1 and len(children) > 1:\n",
        "                # This looks like a table structure\n",
        "                sample_child = children[0]\n",
        "                grandchild_count = len(list(sample_child))\n",
        "\n",
        "                potential_tables.append({\n",
        "                    \"path\": f\"{path}/{node.tag}\",\n",
        "                    \"row_tag\": child_tags[0],\n",
        "                    \"row_count\": len(children),\n",
        "                    \"column_count\": grandchild_count\n",
        "                })\n",
        "\n",
        "        for child in children:\n",
        "            find_potential_tables(child, f\"{path}/{node.tag}\")\n",
        "\n",
        "    find_potential_tables(root)\n",
        "\n",
        "    if potential_tables:\n",
        "        insights_html += f\"<p>Found <b>{len(potential_tables)}</b> potential data table(s):</p>\"\n",
        "        insights_html += \"<ul>\"\n",
        "        for table in potential_tables:\n",
        "            insights_html += f\"<li>Location: <code>{table['path']}</code> - {table['row_count']} rows × {table['column_count']} columns</li>\"\n",
        "        insights_html += \"</ul>\"\n",
        "    else:\n",
        "        insights_html += \"<p>No obvious table structures detected. This might be a document-oriented XML.</p>\"\n",
        "\n",
        "    # Data quality insights\n",
        "    insights_html += f\"<h3 style='color: #A23B72;'>✅ Data Quality Assessment</h3>\"\n",
        "\n",
        "    empty_elements = total_elements - elements_with_text\n",
        "    empty_percentage = (empty_elements / total_elements) * 100\n",
        "\n",
        "    if empty_percentage > 50:\n",
        "        insights_html += f\"<p style='color: #E56B70;'>⚠️ High percentage of empty elements ({empty_percentage:.1f}%). Consider if this is expected for your data model.</p>\"\n",
        "    else:\n",
        "        insights_html += f\"<p>Empty elements: {empty_percentage:.1f}% - This is within normal range.</p>\"\n",
        "\n",
        "    if elements_with_attributes == 0:\n",
        "        insights_html += f\"<p>No attributes found in the XML. This is a simple data structure.</p>\"\n",
        "\n",
        "    # Recommendations\n",
        "    insights_html += f\"<h3 style='color: #A23B72;'>💡 Recommendations</h3>\"\n",
        "    insights_html += \"<ul>\"\n",
        "\n",
        "    if max_depth > 5:\n",
        "        insights_html += \"<li>Deeply nested structure detected. Consider simplifying the hierarchy for better performance.</li>\"\n",
        "\n",
        "    if len(tag_counts) > 20:\n",
        "        insights_html += \"<li>Many different tags detected. This might be a complex data model.</li>\"\n",
        "\n",
        "    if potential_tables:\n",
        "        insights_html += \"<li>Table-like structures detected. You might want to convert these to CSV or database tables.</li>\"\n",
        "\n",
        "    insights_html += \"<li>For better visualization, consider using the 'Data Extraction' tab to view the data in tabular format.</li>\"\n",
        "    insights_html += \"</ul>\"\n",
        "\n",
        "    insights_html += \"</div>\"\n",
        "\n",
        "    return insights_html\n",
        "\n",
        "def visualize_xml(xml_content, input_type):\n",
        "    \"\"\"\n",
        "    Create visualizations from XML data\n",
        "    \"\"\"\n",
        "    root, xml_dict, xml_string, error = parse_xml(xml_content, input_type)\n",
        "\n",
        "    if error:\n",
        "        return f\"Error parsing XML: {error}\"\n",
        "\n",
        "    # Count elements by tag\n",
        "    tag_count = defaultdict(int)\n",
        "\n",
        "    def count_tags(node):\n",
        "        tag_count[node.tag] += 1\n",
        "        for child in node:\n",
        "            count_tags(child)\n",
        "\n",
        "    count_tags(root)\n",
        "\n",
        "    # Create a bar chart of tag frequencies\n",
        "    if tag_count:\n",
        "        fig = px.bar(x=list(tag_count.keys()), y=list(tag_count.values()),\n",
        "                     labels={'x': 'XML Tags', 'y': 'Count'},\n",
        "                     title='Frequency of XML Tags')\n",
        "        return fig\n",
        "    else:\n",
        "        return \"No data available for visualization\"\n",
        "\n",
        "def clean_xml(xml_content, input_type):\n",
        "    \"\"\"\n",
        "    Clean and format XML content\n",
        "    \"\"\"\n",
        "    if input_type == \"file\":\n",
        "        if xml_content is None:\n",
        "            return \"No file uploaded\"\n",
        "        with open(xml_content.name, 'r', encoding='utf-8') as f:\n",
        "            xml_string = f.read()\n",
        "    else:\n",
        "        xml_string = xml_content\n",
        "        if not xml_string.strip():\n",
        "            return \"No XML content provided\"\n",
        "\n",
        "    # Pretty print the XML\n",
        "    try:\n",
        "        soup = BeautifulSoup(xml_string, 'xml')\n",
        "        pretty_xml = soup.prettify()\n",
        "        return pretty_xml\n",
        "    except Exception as e:\n",
        "        return f\"Error formatting XML: {str(e)}\"\n",
        "\n",
        "# Create the Gradio interface\n",
        "with gr.Blocks(theme=gr.themes.Soft(), title=\"XML Data Extractor and Visualizer\") as demo:\n",
        "    gr.Markdown(\"\"\"\n",
        "    # 🔍 XML Data Extractor and Visualizer\n",
        "    Upload an XML file or paste XML content to explore its structure, extract data, and create visualizations.\n",
        "    \"\"\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            input_type = gr.Radio([\"file\", \"text\"], value=\"file\", label=\"Input Type\")\n",
        "            xml_input = gr.File(label=\"Upload XML File\", file_types=[\".xml\"])\n",
        "            xml_text = gr.Textbox(label=\"Or Paste XML Content\", lines=10, visible=False)\n",
        "\n",
        "            def toggle_input(choice):\n",
        "                if choice == \"file\":\n",
        "                    return gr.File(visible=True), gr.Textbox(visible=False)\n",
        "                else:\n",
        "                    return gr.File(visible=False), gr.Textbox(visible=True)\n",
        "\n",
        "            input_type.change(toggle_input, input_type, [xml_input, xml_text])\n",
        "\n",
        "        with gr.Column():\n",
        "            gr.Markdown(\"\"\"\n",
        "            ### 📊 What you can do:\n",
        "            - **View Structure**: See the hierarchical structure of your XML\n",
        "            - **Extract Data**: Convert XML to JSON and detect table structures\n",
        "            - **Generate Insights**: Get meaningful analysis of your XML content\n",
        "            - **Visualize**: Create charts showing tag frequencies\n",
        "            - **Clean XML**: Format and prettify your XML code\n",
        "\n",
        "            ### 🚀 Try with this sample XML:\n",
        "            ```xml\n",
        "            <catalog>\n",
        "              <book id=\"101\">\n",
        "                <author>John Doe</author>\n",
        "                <title>XML Guide</title>\n",
        "                <price>29.99</price>\n",
        "              </book>\n",
        "              <book id=\"102\">\n",
        "                <author>Jane Smith</author>\n",
        "                <title>Python Programming</title>\n",
        "                <price>39.99</price>\n",
        "              </book>\n",
        "            </catalog>\n",
        "            ```\n",
        "            \"\"\")\n",
        "\n",
        "    with gr.Tab(\"📁 XML Structure\"):\n",
        "        gr.Markdown(\"### XML Document Structure\")\n",
        "        structure_btn = gr.Button(\"Extract Structure\", variant=\"primary\")\n",
        "        structure_output = gr.Code(label=\"XML Structure\", language=\"markdown\", lines=15)\n",
        "\n",
        "    with gr.Tab(\"📊 Data Extraction\"):\n",
        "        gr.Markdown(\"### Extracted Data from XML\")\n",
        "        extract_btn = gr.Button(\"Extract Data\", variant=\"primary\")\n",
        "        with gr.Row():\n",
        "            json_output = gr.Code(label=\"JSON Representation\", language=\"json\", lines=15)\n",
        "            table_output = gr.HTML(label=\"Tabular Data\")\n",
        "\n",
        "    with gr.Tab(\"🔍 Insights\"):\n",
        "        gr.Markdown(\"### XML Insights & Analysis\")\n",
        "        insights_btn = gr.Button(\"Generate Insights\", variant=\"primary\")\n",
        "        insights_output = gr.HTML(label=\"XML Insights\")\n",
        "\n",
        "    with gr.Tab(\"📈 Visualization\"):\n",
        "        gr.Markdown(\"### XML Data Visualization\")\n",
        "        viz_btn = gr.Button(\"Create Visualization\", variant=\"primary\")\n",
        "        viz_output = gr.Plot(label=\"Tag Frequency Visualization\")\n",
        "\n",
        "    with gr.Tab(\"✨ XML Cleaner\"):\n",
        "        gr.Markdown(\"### Clean and Format XML\")\n",
        "        clean_btn = gr.Button(\"Clean and Format XML\", variant=\"primary\")\n",
        "        clean_output = gr.Code(label=\"Formatted XML\", language=\"html\", lines=15)\n",
        "\n",
        "    # Set up event handlers\n",
        "    structure_btn.click(\n",
        "        extract_xml_structure,\n",
        "        inputs=[xml_input, input_type],\n",
        "        outputs=structure_output\n",
        "    )\n",
        "\n",
        "    extract_btn.click(\n",
        "        extract_xml_data,\n",
        "        inputs=[xml_input, input_type],\n",
        "        outputs=[json_output, table_output]\n",
        "    )\n",
        "\n",
        "    insights_btn.click(\n",
        "        generate_insights,\n",
        "        inputs=[xml_input, input_type],\n",
        "        outputs=insights_output\n",
        "    )\n",
        "\n",
        "    viz_btn.click(\n",
        "        visualize_xml,\n",
        "        inputs=[xml_input, input_type],\n",
        "        outputs=viz_output\n",
        "    )\n",
        "\n",
        "    clean_btn.click(\n",
        "        clean_xml,\n",
        "        inputs=[xml_input, input_type],\n",
        "        outputs=clean_output\n",
        "    )\n",
        "\n",
        "# For Google Colab, we need to handle the launch differently\n",
        "def launch_in_colab():\n",
        "    # Create a public link\n",
        "    demo.launch(share=True, debug=True)\n",
        "\n",
        "# Launch the interface\n",
        "if __name__ == \"__main__\":\n",
        "    # This will work in both Colab and local environments\n",
        "    try:\n",
        "        import google.colab\n",
        "        IN_COLAB = True\n",
        "    except:\n",
        "        IN_COLAB = False\n",
        "\n",
        "    if IN_COLAB:\n",
        "        launch_in_colab()\n",
        "    else:\n",
        "        demo.launch(debug=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}