# -*- coding: utf-8 -*-
"""NLP-CHUNKING-LLM-GPT2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1g_VZ9LLHcPM1kvDV_4NecSeJi-BrbADT
"""



from google.colab import drive
drive.mount('/content/drive')

!nvidia-smi

!pip install transformers

from transformers import AutoTokenizer

# Load the tokenizer for a specific model (e.g., GPT-2)
tokenizer = AutoTokenizer.from_pretrained("gpt2")

# Tokenize some input text
text = "Hello, how are you?"
tokens = tokenizer(text, return_tensors='pt')
print(tokens)

from transformers import AutoModelForCausalLM

# Load the model for causal language modeling
model = AutoModelForCausalLM.from_pretrained("gpt2")

# Generate text
input_ids = tokenizer.encode("indian cricket", return_tensors='pt')
output = model.generate(input_ids, max_length=50)
generated_text = tokenizer.decode(output[0], skip_special_tokens=True)

print(generated_text)











